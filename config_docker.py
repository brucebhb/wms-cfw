#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dockerå®¹å™¨åŒ–éƒ¨ç½²é…ç½®
"""

import os
from datetime import timedelta


class DockerConfig:
    """Dockerå®¹å™¨åŒ–é…ç½®"""
    
    # åŸºç¡€é…ç½®
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'docker-warehouse-secret-key-2024'
    
    # æ•°æ®åº“é…ç½®
    MYSQL_HOST = os.environ.get('MYSQL_HOST', 'mysql')
    MYSQL_PORT = int(os.environ.get('MYSQL_PORT', 3306))
    MYSQL_USER = os.environ.get('MYSQL_USER', 'warehouse_user')
    MYSQL_PASSWORD = os.environ.get('MYSQL_PASSWORD', 'warehouse_pass')
    MYSQL_DATABASE = os.environ.get('MYSQL_DATABASE', 'warehouse_db')
    
    SQLALCHEMY_DATABASE_URI = (
        f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@'
        f'{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}?charset=utf8mb4'
    )
    
    # å¼‚æ­¥æ•°æ®åº“URL
    ASYNC_DATABASE_URI = (
        f'mysql+aiomysql://{MYSQL_USER}:{MYSQL_PASSWORD}@'
        f'{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}?charset=utf8mb4'
    )
    
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    SQLALCHEMY_ENGINE_OPTIONS = {
        'pool_size': 20,
        'pool_timeout': 20,
        'pool_recycle': 3600,
        'max_overflow': 30,
        'pool_pre_ping': True
    }
    
    # Redisé…ç½®
    REDIS_HOST = os.environ.get('REDIS_HOST', 'redis')
    REDIS_PORT = int(os.environ.get('REDIS_PORT', 6379))
    REDIS_DB = int(os.environ.get('REDIS_DB', 0))
    REDIS_PASSWORD = os.environ.get('REDIS_PASSWORD', None)
    
    if REDIS_PASSWORD:
        REDIS_URL = f'redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'
    else:
        REDIS_URL = f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'
    
    # ä¼šè¯é…ç½®
    PERMANENT_SESSION_LIFETIME = timedelta(hours=6)
    SESSION_COOKIE_SECURE = os.environ.get('SESSION_COOKIE_SECURE', 'False').lower() == 'true'
    SESSION_COOKIE_HTTPONLY = True
    SESSION_COOKIE_SAMESITE = 'Lax'
    
    # æ–‡ä»¶ä¸Šä¼ 
    MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB
    UPLOAD_FOLDER = '/app/uploads'
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')
    LOG_FILE = '/app/logs/warehouse.log'
    LOG_MAX_SIZE = 100 * 1024 * 1024  # 100MB
    LOG_BACKUP_COUNT = 5
    
    # æ€§èƒ½é…ç½®
    ENABLE_ASYNC = os.environ.get('ENABLE_ASYNC', 'True').lower() == 'true'
    ENABLE_CACHE = os.environ.get('ENABLE_CACHE', 'True').lower() == 'true'
    CACHE_DEFAULT_TIMEOUT = int(os.environ.get('CACHE_DEFAULT_TIMEOUT', 300))
    
    # å®‰å…¨é…ç½®
    WTF_CSRF_ENABLED = True
    WTF_CSRF_TIME_LIMIT = 3600
    
    # è°ƒè¯•é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒå…³é—­ï¼‰
    DEBUG = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    TESTING = False
    
    # åº”ç”¨é…ç½®
    WAREHOUSE_NAMES = {
        1: 'å¹³æ¹–ä»“',
        2: 'æ˜†å±±ä»“', 
        3: 'æˆéƒ½ä»“',
        4: 'å‡­ç¥¥åŒ—æŠ•ä»“',
        5: 'å‡­ç¥¥ä¿ç¨ä»“'
    }
    
    # åˆ†é¡µé…ç½®
    ITEMS_PER_PAGE = 20
    MAX_ITEMS_PER_PAGE = 100
    
    # ç¼“å­˜é…ç½®
    CACHE_TYPE = 'redis'
    CACHE_REDIS_URL = REDIS_URL
    CACHE_DEFAULT_TIMEOUT = CACHE_DEFAULT_TIMEOUT
    
    # å¼‚æ­¥ä»»åŠ¡é…ç½®
    ASYNC_POOL_SIZE = int(os.environ.get('ASYNC_POOL_SIZE', 10))
    ASYNC_TIMEOUT = int(os.environ.get('ASYNC_TIMEOUT', 30))
    
    # ç›‘æ§é…ç½®
    ENABLE_METRICS = os.environ.get('ENABLE_METRICS', 'True').lower() == 'true'
    METRICS_PORT = int(os.environ.get('METRICS_PORT', 9090))
    
    @staticmethod
    def init_app(app):
        """åˆå§‹åŒ–åº”ç”¨é…ç½®"""
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs('/app/logs', exist_ok=True)
        os.makedirs('/app/uploads', exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        import logging
        from logging.handlers import RotatingFileHandler
        
        if not app.debug and not app.testing:
            # æ–‡ä»¶æ—¥å¿—
            file_handler = RotatingFileHandler(
                DockerConfig.LOG_FILE,
                maxBytes=DockerConfig.LOG_MAX_SIZE,
                backupCount=DockerConfig.LOG_BACKUP_COUNT
            )
            file_handler.setFormatter(logging.Formatter(
                '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
            ))
            file_handler.setLevel(getattr(logging, DockerConfig.LOG_LEVEL))
            app.logger.addHandler(file_handler)
            
            # æ§åˆ¶å°æ—¥å¿—
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter(
                '%(asctime)s %(levelname)s: %(message)s'
            ))
            console_handler.setLevel(logging.INFO)
            app.logger.addHandler(console_handler)
            
            app.logger.setLevel(getattr(logging, DockerConfig.LOG_LEVEL))
            app.logger.info('ğŸ³ ä»“åº“ç®¡ç†ç³»ç»Ÿå®¹å™¨åŒ–å¯åŠ¨')


class DevelopmentDockerConfig(DockerConfig):
    """å¼€å‘ç¯å¢ƒDockeré…ç½®"""
    DEBUG = True
    LOG_LEVEL = 'DEBUG'


class ProductionDockerConfig(DockerConfig):
    """ç”Ÿäº§ç¯å¢ƒDockeré…ç½®"""
    DEBUG = False
    LOG_LEVEL = 'INFO'
    SESSION_COOKIE_SECURE = True
    
    @classmethod
    def init_app(cls, app):
        DockerConfig.init_app(app)
        
        # ç”Ÿäº§ç¯å¢ƒé¢å¤–é…ç½®
        import logging
        from logging import StreamHandler
        
        # é”™è¯¯é‚®ä»¶é€šçŸ¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        mail_handler = None
        if os.environ.get('MAIL_SERVER'):
            mail_handler = SMTPHandler(
                mailhost=(os.environ.get('MAIL_SERVER'), 587),
                fromaddr=os.environ.get('MAIL_FROM'),
                toaddrs=os.environ.get('MAIL_TO', '').split(','),
                subject='ä»“åº“ç®¡ç†ç³»ç»Ÿé”™è¯¯',
                credentials=(
                    os.environ.get('MAIL_USERNAME'),
                    os.environ.get('MAIL_PASSWORD')
                ),
                secure=()
            )
            mail_handler.setLevel(logging.ERROR)
            app.logger.addHandler(mail_handler)


# é…ç½®æ˜ å°„
config = {
    'development': DevelopmentDockerConfig,
    'production': ProductionDockerConfig,
    'default': DevelopmentDockerConfig
}
