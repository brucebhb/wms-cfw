"""
æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å™¨
ä¸“é—¨ç”¨äºä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ï¼Œä¸ç¦ç”¨åŠŸèƒ½
"""

from flask import current_app
from sqlalchemy import text, event
from sqlalchemy.engine import Engine
import time
import logging

class DatabaseQueryOptimizer:
    """æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.slow_queries = []
        self.query_cache = {}
        self.optimization_applied = False
    
    @staticmethod
    def init_app(app):
        """åˆå§‹åŒ–æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–"""
        optimizer = DatabaseQueryOptimizer()
        
        # 1. å¯ç”¨æŸ¥è¯¢ç›‘æ§
        optimizer.setup_query_monitoring()
        
        # 2. åº”ç”¨æŸ¥è¯¢ä¼˜åŒ–
        optimizer.apply_query_optimizations()
        
        # 3. è®¾ç½®è¿æ¥æ± ä¼˜åŒ–
        optimizer.optimize_connection_pool(app)
        
        app.logger.info("ğŸ—ƒï¸ æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å™¨å·²å¯ç”¨")
        return optimizer
    
    def setup_query_monitoring(self):
        """è®¾ç½®æŸ¥è¯¢ç›‘æ§"""
        @event.listens_for(Engine, "before_cursor_execute")
        def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            context._query_start_time = time.time()
        
        @event.listens_for(Engine, "after_cursor_execute")
        def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            total = time.time() - context._query_start_time
            
            # è®°å½•æ…¢æŸ¥è¯¢ï¼ˆè¶…è¿‡100msï¼‰
            if total > 0.1:
                self.slow_queries.append({
                    'query': statement[:200] + '...' if len(statement) > 200 else statement,
                    'time': total,
                    'timestamp': time.time()
                })
                
                # åªä¿ç•™æœ€è¿‘çš„50ä¸ªæ…¢æŸ¥è¯¢
                if len(self.slow_queries) > 50:
                    self.slow_queries = self.slow_queries[-50:]
                
                current_app.logger.warning(f"æ…¢æŸ¥è¯¢æ£€æµ‹: {total:.3f}s - {statement[:100]}...")
    
    def apply_query_optimizations(self):
        """åº”ç”¨æŸ¥è¯¢ä¼˜åŒ–"""
        if self.optimization_applied:
            return
        
        try:
            from app import db
            
            # 1. åˆ›å»ºå…³é”®ç´¢å¼•
            self.create_performance_indexes(db)
            
            # 2. ä¼˜åŒ–æŸ¥è¯¢è®¾ç½®
            self.optimize_query_settings(db)
            
            self.optimization_applied = True
            current_app.logger.info("âœ… æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å·²åº”ç”¨")
            
        except Exception as e:
            current_app.logger.error(f"æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {e}")
    
    def create_performance_indexes(self, db):
        """åˆ›å»ºæ€§èƒ½ç´¢å¼•"""
        indexes = [
            # å…¥åº“è®°å½•ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_inbound_time ON inbound_records(inbound_time)",
            "CREATE INDEX IF NOT EXISTS idx_inbound_customer ON inbound_records(customer_name)",
            "CREATE INDEX IF NOT EXISTS idx_inbound_warehouse ON inbound_records(operated_warehouse_id)",
            
            # å‡ºåº“è®°å½•ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_outbound_time ON outbound_records(departure_time)",
            "CREATE INDEX IF NOT EXISTS idx_outbound_customer ON outbound_records(customer_name)",
            "CREATE INDEX IF NOT EXISTS idx_outbound_warehouse ON outbound_records(operated_warehouse_id)",
            
            # æ¥æ”¶è®°å½•ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_receive_time ON receive_records(inbound_time)",
            "CREATE INDEX IF NOT EXISTS idx_receive_batch ON receive_records(batch_no)",
            
            # åº“å­˜ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_inventory_warehouse ON inventory(warehouse_id)",
            "CREATE INDEX IF NOT EXISTS idx_inventory_customer ON inventory(customer_name)",
            
            # ç”¨æˆ·ç›¸å…³ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_user_username ON users(username)",
            "CREATE INDEX IF NOT EXISTS idx_user_active ON users(is_active)",
        ]
        
        for index_sql in indexes:
            try:
                db.session.execute(text(index_sql))
                db.session.commit()
            except Exception as e:
                # ç´¢å¼•å¯èƒ½å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                db.session.rollback()
                if "already exists" not in str(e).lower():
                    current_app.logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
    
    def optimize_query_settings(self, db):
        """ä¼˜åŒ–æŸ¥è¯¢è®¾ç½®"""
        try:
            # MySQLç‰¹å®šä¼˜åŒ–
            optimizations = [
                "SET SESSION query_cache_type = ON",
                "SET SESSION query_cache_size = 67108864",  # 64MB
                "SET SESSION tmp_table_size = 67108864",    # 64MB
                "SET SESSION max_heap_table_size = 67108864", # 64MB
                "SET SESSION join_buffer_size = 2097152",   # 2MB
                "SET SESSION sort_buffer_size = 2097152",   # 2MB
            ]
            
            for opt_sql in optimizations:
                try:
                    db.session.execute(text(opt_sql))
                except Exception as e:
                    # æŸäº›è®¾ç½®å¯èƒ½ä¸è¢«æ”¯æŒï¼Œå¿½ç•¥é”™è¯¯
                    pass
            
            db.session.commit()
            
        except Exception as e:
            db.session.rollback()
            current_app.logger.warning(f"æŸ¥è¯¢è®¾ç½®ä¼˜åŒ–å¤±è´¥: {e}")
    
    def optimize_connection_pool(self, app):
        """ä¼˜åŒ–è¿æ¥æ± è®¾ç½®"""
        # è¿™äº›è®¾ç½®å·²åœ¨ app/__init__.py ä¸­åº”ç”¨
        current_app.logger.info("è¿æ¥æ± ä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")
    
    def get_slow_queries(self):
        """è·å–æ…¢æŸ¥è¯¢åˆ—è¡¨"""
        return self.slow_queries
    
    def clear_slow_queries(self):
        """æ¸…é™¤æ…¢æŸ¥è¯¢è®°å½•"""
        self.slow_queries.clear()
    
    @staticmethod
    def optimize_query(query):
        """ä¼˜åŒ–å•ä¸ªæŸ¥è¯¢"""
        # æ·»åŠ æŸ¥è¯¢æç¤º
        if "SELECT" in query.upper() and "LIMIT" not in query.upper():
            # ä¸ºæ²¡æœ‰LIMITçš„æŸ¥è¯¢æ·»åŠ åˆç†çš„é™åˆ¶
            if "ORDER BY" in query.upper():
                query += " LIMIT 1000"
            else:
                query += " ORDER BY id DESC LIMIT 1000"
        
        return query
    
    @staticmethod
    def create_optimized_query_builder():
        """åˆ›å»ºä¼˜åŒ–çš„æŸ¥è¯¢æ„å»ºå™¨"""
        class OptimizedQuery:
            def __init__(self, model):
                self.model = model
                self.query = model.query
            
            def filter_by_date_range(self, date_field, start_date, end_date):
                """ä¼˜åŒ–çš„æ—¥æœŸèŒƒå›´æŸ¥è¯¢"""
                if start_date and end_date:
                    return self.query.filter(
                        date_field >= start_date,
                        date_field <= end_date
                    ).order_by(date_field.desc())
                return self.query.order_by(date_field.desc())
            
            def paginate_optimized(self, page, per_page=20):
                """ä¼˜åŒ–çš„åˆ†é¡µæŸ¥è¯¢"""
                # ä½¿ç”¨æ›´å°çš„é¡µé¢å¤§å°ä»¥æé«˜æ€§èƒ½
                actual_per_page = min(per_page, 50)
                return self.query.paginate(
                    page=page,
                    per_page=actual_per_page,
                    error_out=False
                )
        
        return OptimizedQuery

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_optimizer = None

def get_db_optimizer():
    """è·å–æ•°æ®åº“ä¼˜åŒ–å™¨å®ä¾‹"""
    global _optimizer
    if _optimizer is None:
        _optimizer = DatabaseQueryOptimizer()
    return _optimizer

def init_db_optimization(app):
    """åˆå§‹åŒ–æ•°æ®åº“ä¼˜åŒ–"""
    return DatabaseQueryOptimizer.init_app(app)
